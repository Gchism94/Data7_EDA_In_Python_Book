[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data 7 Exploratory Data Analysis In Python Book",
    "section": "",
    "text": "Here you will find a collection of workshops prepared by the staff of the Data Science Institute\n\n\n\n\n\nExploring a novel data set and produce an HTML interactive reports\n\n\n\n\n\n\n\nExploring the normality of numerical columns in a novel data set\n\n\n\n\n\n\n\nUsing data transformation to correct non-normality in numerical data\n\n\n\n\n\n\n\nExploring, visualizing, and imputing outliers and missing values (NAs) in a novel data set\n\n\n\n\n\n\n\nAssess relationships within a novel data set\n\nVisit our available Digital Learning Resources Library!\n\nCreated: 09/14/2022 (G. Chism); Last update: 09/14/2022\n CC BY-NC-SA"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Exploratory data analysis is an essential first step towards determining the validity of your data and should be performed throughout the data pipeline. However, EDA is often performed too late or not at all. The Python programming language, is a widely used open source platform for data analysis and data visualization. This is because of the variety of libraries available and attentive community devoted to data analysis.\nHere, we utilize the pandas and pandas-profiling libraries to conduct preliminary exploratory data analysis aimed at diagnosing any major issues with an imported data set. pandas and pandas-profiling offers a clean and straightforward methodology to uncover issues such as data outliers, missing data, as well as summary statistical reports."
  },
  {
    "objectID": "intro.html#what-are-some-important-data-set-characteristics",
    "href": "intro.html#what-are-some-important-data-set-characteristics",
    "title": "Introduction",
    "section": "What are Some Important Data Set Characteristics?",
    "text": "What are Some Important Data Set Characteristics?\nThere are several characteristics that are arguably important, but we will only consider those covered in this workshop series. Let’s start with the fundamentals that will help guide us."
  },
  {
    "objectID": "intro.html#diagnostics",
    "href": "intro.html#diagnostics",
    "title": "Introduction",
    "section": "Diagnostics",
    "text": "Diagnostics\nWhen importing data sets, it is important to consider characteristics about the data columns, rows, and individual cells.\n\n\nVariables\nName of each variable\n\n\n   Pregnancies  Glucose  BloodPressure  ...  Age  Outcome  Age_group\n0            6      148             72  ...   50        1     Middle\n1            1       85             66  ...   31        0     Middle\n2            8      183             64  ...   32        1     Middle\n3            1       89             66  ...   21        0      Young\n4            0      137             40  ...   33        1     Middle\n\n[5 rows x 10 columns]\n\n\n\n\nTypes\nData type of each variable\n\n\nPregnancies                   int64\nGlucose                       int64\nBloodPressure                 int64\nSkinThickness                 int64\nInsulin                       int64\nBMI                         float64\nDiabetesPedigreeFunction    float64\nAge                           int64\nOutcome                       int64\nAge_group                    object\ndtype: object\n\n\n\nNumerical: Continuous\nMeasurable numbers that are fractional or decimal and cannot be counted (e.g., time, height, weight)\n\n\n\n\n\n\n\nNumerical: Discrete\nCountable whole numbers or integers (e.g., number of successes or failures)\n\n\n\n\n\n\n\n\nCategorical: Nominal\nLabeling variables without any order or quantitative value (e.g., hair color, nationality)\n\n\n\n\n\n\n\nCategorical: Ordinal\nWhere there is a hierarchical order along a scale (e.g., ranks, letter grades, age groups)\n\n\n\n\n\n\n\n\nMissing Values (NAs)\nCells, rows, or columns without data\n\nMissing percent: percentage of missing values * Unique count: number of unique values.\nUnique rate: rate of unique value - unique count / total number of observations.\n\n\n\n   Pregnancies  Glucose  BloodPressure  ...  Outcome  Age_group  Outcome1\n0          NaN    148.0           72.0  ...      1.0     Middle       Yes\n1          1.0     85.0            NaN  ...      0.0     Middle        No\n2          8.0    183.0           64.0  ...      1.0     Middle       Yes\n3          1.0     89.0           66.0  ...      0.0      Young        No\n4          0.0    137.0           40.0  ...      1.0     Middle       Yes\n\n[5 rows x 11 columns]"
  },
  {
    "objectID": "intro.html#summary-statistics",
    "href": "intro.html#summary-statistics",
    "title": "Introduction",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nAbove we described some properties of data. However, you will need to know some descriptive characteristics of your data before you can move forward. Enter, summary statistics.\nSummary statistics allow you to summarize large amounts of information about your data as quickly as possible.\n\nCentral Tendency\nMeasuring a central property of your data. Some examples you’ve probably heard of are:\n\nMean: Average value\nMedian: Middle value\nMode: Most common value\n\n\n\n\n\n\nNotice that all values of central tendency can be pretty similar in this figure.\n\n\n\n\n\nHowever, in this figure, all measures are different. This will be important when we discuss statistical dispersion in chapter 3.\n\n\n\n\n\nStatistical Dispersion\nMeasure of data variability, scatter, or spread. Some examples you may have heard of:\n\nStandard deviation (SD): The amount of variation that occurs in a set of values.\nInterquartile range (IQR): The difference between the 75th and 25th percentiles\nOutliers: A value outside of \\(1.5 * IQR\\)\n\n\n\n\n\n\n\n\nDistribution Shape\nMeasures of describing the shape of a distribution, usually compared to a normal distribution (bell-curve)\n\nSkewness: The symmetry of the distribution\nKurtosis: The tailedness of the distribution\n\n\n\n\n\n\n\n\nStatistical Dependence (Correlation)\nMeasure of causality between two random variables (statistically). Notably, we approximate causality with correlations (see correlation \\(\\neq\\) causation)\n\nNumerical values, but you can compare numericals across categories (see the first plot above)."
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html",
    "href": "DiagnosingLikeDataDoctor.html",
    "title": "Exploratory Data Analysis in Python - Diagnosing like a Data Doctor",
    "section": "",
    "text": "Exploring a novel data set and produce an HTML interactive reports"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#objectives",
    "href": "DiagnosingLikeDataDoctor.html#objectives",
    "title": "Exploratory Data Analysis in Python - Diagnosing like a Data Doctor",
    "section": "Objectives",
    "text": "Objectives\n\nLoad and explore a data set with publication quality tables\nDiagnose outliers and missing values in a data set\nPrepare an HTML summary report showcasing properties of a data set"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#required-setup",
    "href": "DiagnosingLikeDataDoctor.html#required-setup",
    "title": "Exploratory Data Analysis in Python - Diagnosing like a Data Doctor",
    "section": "Required Setup",
    "text": "Required Setup\nWe first need to prepare our environment with the necessary libraries and set a global theme for publishable plots in seaborn.\n\n# Import all required libraries\n# Data analysis and manipulation\nimport pandas as pd\n# Working with arrays\nimport numpy as np\n# Statistical visualization\nimport seaborn as sns\n# Matlab plotting for Python\nimport matplotlib.pyplot as plt\n# Data analysis\nimport statistics as stat\n# Predictive data analysis: process data \nfrom sklearn import preprocessing as pproc\nimport scipy.stats as stats\n# Visualizing missing values\nimport missingno as msno\n# Interactive HTML EDA report\nfrom pandas_profiling import ProfileReport\n\n# Increase font size of all Seaborn plot elements\nsns.set(font_scale = 1.25)"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#load-and-examine-a-data-set",
    "href": "DiagnosingLikeDataDoctor.html#load-and-examine-a-data-set",
    "title": "Exploratory Data Analysis in Python - Diagnosing like a Data Doctor",
    "section": "Load and Examine a Data Set",
    "text": "Load and Examine a Data Set\n\nLoad data and view\nExamine columns and data types\nDefine box plots\nDescribe meta data\n\nWe will be using open source data from UArizona researchers for Test, Trace, Treat (T3) efforts offers two clinical diagnostic tests (Antigen, RT-PCR) to determine whether an individual is currently infected with the COVID-19 virus. (Merchant et al. 2022)\n\n# Read csv \ndata = pd.read_csv(\"data/daily_summary.csv\")\n\n# What does the data look like\ndata.head()\n\n  result_date      affil_category  ... test_count          test_source\n0  2020-08-04            Employee  ...          5        Campus Health\n1  2020-08-04            Employee  ...          0        Campus Health\n2  2020-08-04            Employee  ...          1  Test All Test Smart\n3  2020-08-04            Employee  ...          0  Test All Test Smart\n4  2020-08-04  Off-Campus Student  ...          9        Campus Health\n\n[5 rows x 6 columns]"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#diagnose-your-data",
    "href": "DiagnosingLikeDataDoctor.html#diagnose-your-data",
    "title": "Exploratory Data Analysis in Python - Diagnosing like a Data Doctor",
    "section": "Diagnose your Data",
    "text": "Diagnose your Data\n\n# What are the properties of the data\ndiagnose = data.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9180 entries, 0 to 9179\nData columns (total 6 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   result_date     9180 non-null   object\n 1   affil_category  9180 non-null   object\n 2   test_type       9180 non-null   object\n 3   test_result     9180 non-null   object\n 4   test_count      9180 non-null   int64 \n 5   test_source     9180 non-null   object\ndtypes: int64(1), object(5)\nmemory usage: 430.4+ KB\n\n\n\nColumn: name of each variable\nNon-Null Count: number of missing values\nDType: data type of each variable"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#summary-statistics-of-your-data",
    "href": "DiagnosingLikeDataDoctor.html#summary-statistics-of-your-data",
    "title": "Exploratory Data Analysis in Python - Diagnosing like a Data Doctor",
    "section": "Summary Statistics of your Data",
    "text": "Summary Statistics of your Data\n\nNumerical Variables\n\n# Summary statistics of our numerical columns\ndata.describe()\n\n        test_count\ncount  9180.000000\nmean     46.771024\nstd     129.475844\nmin       0.000000\n25%       0.000000\n50%       2.000000\n75%      16.000000\nmax    1472.000000\n\n\n\ncount: number of observations\nmean: arithmetic mean (average value)\nstd: standard deviation\nmin: minimum value\n25%: 1/4 quartile, 25th percentile\n50%: median, 50th percentile\n75%: 3/4 quartile, 75th percentile\nmax: maximum value\n\n\n\n\nOutliers\nValues outside of \\(1.5 * IQR\\)\n\n\n\nImage Credit: CÉDRIC SCHERER\n\n\n\nThere are several numerical variables that have outliers above, let’s see what the data look like with and without them\n\nCreate a table with columns containing outliers\nPlot outliers in a box plot and histogram\n\n\n# Make a copy of the data \ndataCopy = data.copy()\n\n# Select only numerical columns\ndataRed = dataCopy.select_dtypes(include = np.number)\n\n# List of numerical columns\ndataRedColsList = dataRed.columns[...]\n\n# For all values in the numerical column list from above\nfor i_col in dataRedColsList:\n  # List of the values in i_col\n  dataRed_i = dataRed.loc[:,i_col]\n  \n  # Define the 25th and 75th percentiles\n  q25, q75 = round((dataRed_i.quantile(q=0.25)), 3), round((dataRed_i.quantile(q=0.75)), 3)\n  \n  # Define the interquartile range from the 25th and 75th percentiles defined above\n  IQR = round((q75 - q25), 3)\n  \n  # Calculate the outlier cutoff \n  cut_off = IQR * 1.5\n  \n  # Define lower and upper cut-offs\n  lower, upper = round((q25 - cut_off), 3), round((q75 + cut_off), 3)\n  \n  # Print the values\n  print(' ')\n  \n  # For each value of i_col, print the 25th and 75th percentiles and IQR\n  print(i_col, 'q25=', q25, 'q75=', q75, 'IQR=', IQR)\n  \n  # Print the lower and upper cut-offs\n  print('lower, upper:', lower, upper)\n\n  # Count the number of outliers outside the (lower, upper) limits, print that value\n  print('Number of Outliers: ', dataRed_i[(dataRed_i < lower) | (dataRed_i > upper)].count())\n\n \ntest_count q25= 0.0 q75= 16.0 IQR= 16.0\nlower, upper: -24.0 40.0\nNumber of Outliers:  1721\n\n\n\nq25: 1/4 quartile, 25th percentile\nq75: 3/4 quartile, 75th percentile\nIQR: interquartile range (q75-q25)\nlower: lower limit of \\(1.5*IQR\\) used to calculate outliers\nupper: upper limit of \\(1.5*IQR\\) used to calculate outliers\n\n\n# Change theme to \"white\"\nsns.set_style(\"white\")\n\n# Select only numerical columns\ndataRedColsList = data.select_dtypes(include = np.number)\n\n# Melt data from wide-to-long format\ndata_melted = pd.melt(dataRedColsList)\n\n# Boxplot of all numerical variables\nsns.boxplot(data = data_melted, x = 'variable', y = 'value', hue = 'variable' , width = 0.20)\n\n\n\n\nNote the extreme number of outliers represented in the boxplot\n\n# Find Q1, Q3, and interquartile range (IQR) for each column\nQ1 = dataRedColsList.quantile(q = .25)\nQ3 = dataRedColsList.quantile(q = .75)\nIQR = dataRedColsList.apply(stats.iqr)\n\n# Only keep rows in dataframe that have values within 1.5*IQR of Q1 and Q3\ndata_clean = dataRedColsList[~((dataRedColsList < (Q1 - 1.5 * IQR)) | (dataRedColsList > (Q3 + 1.5 * IQR))).any(axis = 1)]\n\n# Melt data from wide-to-long format\ndata_clean_melted =  pd.melt(data_clean)\n\n# Boxplot of all numerical variables, with outliers removed via the IQR cutoff criteria\nsns.boxplot(data = data_clean_melted, x = 'variable', y = 'value', hue = 'variable' , width = 0.20)\n\n\n\n\nBut the distribution changes dramatically when we remove outliers with the IQR method (see above). Interestingly, there are a new set of “outliers” which results from a new IQR being calculated.\n\n\nMissing Values (NAs)\n\nTable showing the extent of NAs in columns containing them\n\n\n# Copy of the data\ndataNA = data\n\n# Randomly add NAs to all columns replacing 10% of values\nfor col in dataNA.columns:\n    dataNA.loc[dataNA.sample(frac = 0.1).index, col] = np.nan\n\n# Sum of NAs in each column (should be the same, 10% of all)   \ndataNA.isnull().sum()\n\nresult_date       918\naffil_category    918\ntest_type         918\ntest_result       918\ntest_count        918\ntest_source       918\ndtype: int64\n\n\nBar plot showing all NA values in each column. Since we randomly produced a set amount above the numbers will all be the same.\n\n# Bar plot showing the number of NAs in each column\nmsno.bar(dataNA, figsize = (8, 8), fontsize = 10)\n\n\n\n\n\n\n\nCategorical Variables\n\n# Select only categorical columns (objects) and describe\ndata.describe(exclude = [np.number]) \n\n       result_date      affil_category  ... test_result          test_source\ncount         8262                8262  ...        8262                 8262\nunique         541                   4  ...           3                    2\ntop     2020-09-16  Off-Campus Student  ...    Positive  Test All Test Smart\nfreq            24                3027  ...        4156                 4583\n\n[4 rows x 5 columns]\n\n\n\ncount: number of values in the column\nunique: the number of unique categories\ntop: category with the most observations\nfreq: number of observations in the top category"
  },
  {
    "objectID": "DiagnosingLikeDataDoctor.html#produce-an-html-summary-of-a-data-set",
    "href": "DiagnosingLikeDataDoctor.html#produce-an-html-summary-of-a-data-set",
    "title": "Exploratory Data Analysis in Python - Diagnosing like a Data Doctor",
    "section": "Produce an HTML Summary of a Data Set",
    "text": "Produce an HTML Summary of a Data Set\n\n# Producing a pandas-profiling report \n# profile = ProfileReport(data, title = \"Pandas Profiling Report\")\n\n# HTML output\n# profile.to_widgets()\n\n\n\n\n\nMerchant, Nirav C, Jim Davis, George H Franks, Chun Ly, Fernando Rios, Todd Wickizer, Gary D Windham, and Michelle Yung. 2022. “University of Arizona Test-Trace-Treat COVID-19 Testing Results.” University of Arizona Research Data Repository. https://doi.org/10.25422/AZU.DATA.14869740.V3."
  }
]